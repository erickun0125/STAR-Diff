\documentclass[letterpaper, 10pt, conference]{ieeeconf}

% Packages
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{bm}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning,calc}

% Custom commands
\newcommand{\real}{\mathbb{R}}
\newcommand{\SE}{\mathrm{SE}}
\newcommand{\SO}{\mathrm{SO}}
\newcommand{\pabs}{\mathbf{p}_{\text{abs}}}
\newcommand{\prel}{\mathbf{p}_{\text{rel}}}
\newcommand{\ptrocar}{\mathbf{p}_{T}}
\newcommand{\lambdatrocar}{\lambda_{\text{trocar}}}
\newcommand{\gamrel}{\gamma_{\text{rel}}}
\newcommand{\xrcm}{x_{\text{RCM}}}
\newcommand{\Mrcm}{\mathcal{M}_{\text{RCM}}}
\newcommand{\Ptro}{\mathbf{P}_{\text{tro}}}
\newcommand{\Pcam}{\mathbf{P}_{\text{cam}}}

\title{\LARGE \bf STAR-Diff: Surgical Trocar-Adaptive, RCM-aware Diffusion Policy}

\author{Anonymous Authors}

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%==============================================================================
% ABSTRACT
%==============================================================================
\begin{abstract}
Automating laparoscopic surgery holds significant promise for improving surgical outcomes. While some recent works have addressed varying trocar positions, they rely on wrist-mounted cameras to implicitly infer trocar configurations and use relative pose actions without explicitly constraining the action space to the RCM manifold—potentially causing issues when low-level controllers must project infeasible commands onto valid motions. Moreover, most prior works depend on proprietary systems such as the da Vinci Surgical System with articulated EndoWrist mechanisms, which alleviate RCM constraint challenges. In contrast, we present \textbf{STAR-Diff} (\textbf{S}urgical \textbf{T}rocar-\textbf{A}daptive, \textbf{R}CM-aware \textbf{Diff}usion Policy), a novel imitation learning framework designed for standard 6-DoF manipulators without specialized surgical wrists, using only a fixed external camera. Our key contributions are: (1) \textbf{RCM-aware action space design}—we propose four parameterizations of the 4-dimensional RCM constraint manifold, categorized as fully-relative or mixed (relative-absolute), each guaranteeing constraint satisfaction by construction; and (2) \textbf{trocar-centric observation space design}—we introduce trocar-centric spatial encoding that augments RGB images with dense coordinate maps expressed in the trocar frame. For mixed parameterizations containing trocar-invariant components, we propose a hierarchical architecture where a diffusion model predicts the trocar-invariant component and a deterministic network completes the trocar-dependent component. STAR-Diff democratizes surgical automation beyond proprietary platforms, enabling generalization to unseen trocar configurations while guaranteeing zero RCM constraint violations by construction.
\end{abstract}

%==============================================================================
% SECTION 1: INTRODUCTION
%==============================================================================
\section{Introduction}
\label{sec:introduction}

Minimally invasive surgery (MIS), particularly laparoscopic procedures, has revolutionized surgical practice by reducing patient trauma, hospital stays, and recovery times \cite{mack2001minimally}. However, the inherent challenges of operating through small incisions—limited field of view, reduced haptic feedback, and constrained instrument motion—place significant cognitive and physical demands on surgeons. Robot-assisted surgical systems, exemplified by the da Vinci platform \cite{intuitive2023davinci}, have emerged as transformative tools that enhance precision and ergonomics. Yet, the potential for autonomous execution of surgical subtasks remains largely unrealized in clinical settings.

Recent advances in robot learning, particularly imitation learning and diffusion-based policies \cite{chi2023diffusion, zhao2023learning}, have demonstrated remarkable success in contact-rich manipulation tasks. Several works have applied these techniques to surgical automation \cite{scheikl2024movement, xu2021surrol}, achieving impressive results on benchmark tasks such as peg transfer, tissue manipulation, and suturing. However, critical limitations in existing approaches fundamentally constrain their practical applicability.

\subsection{Limitations of Existing Approaches}

\textbf{(1) Implicit RCM Handling without Constraint Guarantees.} While some recent works have addressed varying trocar positions \cite{kim2024srt, kim2024srth, chiu2024suturebot}, they do so without explicitly modeling the RCM constraint manifold. These approaches typically:
\begin{itemize}
    \item Rely on \textbf{wrist-mounted cameras} to implicitly infer trocar configurations from visual observations, rather than explicitly conditioning on trocar frame information.
    \item Use \textbf{relative pose actions} with respect to the current end-effector pose, which does not inherently respect RCM constraints.
    \item Do not constrain the action space to the \textbf{RCM-feasible manifold}, meaning the policy can output actions that violate the RCM constraint.
\end{itemize}

This design leads to a critical issue: when the low-level controller receives an infeasible action command that would violate the RCM constraint, it must project or clamp the command onto a feasible motion. This projection can introduce \textbf{tracking errors}, cause \textbf{discontinuous motions}, and potentially lead to \textbf{task failures}—especially in precision-critical surgical manipulation.

\textbf{(2) Reliance on Specialized Hardware.} The majority of surgical automation research uses the \textbf{da Vinci Research Kit (dVRK)} \cite{kazanzides2014open}, which features 7+ DoF instruments with articulated ``wrist'' joints (EndoWrist). This redundancy significantly relaxes the RCM constraint's impact on end-effector reachability—the wrist can compensate for approach angles that would be impossible with a rigid instrument. Consequently, prior works have not needed to carefully design RCM-aware action spaces for standard manipulators.

\textbf{(3) Trocar Variation in Clinical Practice.} Even for approaches that handle varying trocars implicitly, clinical practice demands robust adaptation to diverse trocar configurations based on:
\begin{itemize}
    \item \textbf{Patient anatomy}: Body habitus, organ size, and pathology location necessitate patient-specific port configurations \cite{reynolds2001practical}.
    \item \textbf{Procedure type}: Different procedures require distinct trocar arrangements.
    \item \textbf{Surgeon preference}: Individual surgeons develop personalized port placement preferences \cite{murphy2001surgeon}.
\end{itemize}

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/teaser.pdf}
    \caption{\textbf{Problem Overview.} (a) Existing approaches either assume fixed trocars or handle varying trocars implicitly via wrist cameras without RCM constraint guarantees. (b) STAR-Diff explicitly parameterizes the RCM constraint manifold as the action space, guaranteeing feasibility by construction, and uses trocar-centric observation encoding with a fixed external camera.}
    \label{fig:teaser}
\end{figure}

\subsection{Our Setting: Democratizing Surgical Automation}

In this work, we target a challenging and practical setting:

\textbf{(1) Standard 6-DoF Manipulator without EndoWrist.} We assume a general-purpose industrial manipulator (e.g., Fairino FR5) equipped with a rigid laparoscopic instrument. Without additional wrist DoF, the RCM constraint directly couples tip position, approach angle, and axial rotation through the trocar point. This makes \textbf{explicit RCM-aware action space design} essential.

\textbf{(2) Fixed External Camera without Wrist Sensing.} We assume a single monocular camera mounted externally, observing the surgical workspace from a fixed viewpoint. Unlike wrist-mounted cameras that provide implicit trocar-frame observations, this configuration requires explicit handling of the observation-action frame mismatch.

We choose this setting to \textbf{democratize surgical automation research}: enabling experimentation with commodity hardware rather than requiring proprietary platforms or specialized sensing.

\subsection{Our Approach: STAR-Diff}

STAR-Diff addresses the above limitations through:

\textbf{(1) RCM-aware Action Space Design.} We directly parameterize the action space using the 4-dimensional RCM constraint manifold $\Mrcm$. We identify four candidate parameterizations:
\begin{itemize}
    \item \textbf{Fully-relative}: Both components expressed in the trocar frame.
    \item \textbf{Mixed (relative-absolute)}: One trocar-invariant absolute component and one trocar-dependent relative component.
\end{itemize}
\textbf{All parameterizations guarantee RCM compliance by construction}—the low-level controller never receives infeasible commands.

\textbf{(2) Trocar-Centric Observation Space Design.} We introduce \textbf{trocar-centric spatial encoding} that augments RGB observations with per-pixel 3D coordinates expressed in the trocar frame, explicitly bridging the observation-action frame gap without relying on wrist cameras.

\textbf{(3) Architecture Design.} For fully-relative parameterizations, we use a single diffusion model. For mixed parameterizations, we propose a \textbf{hierarchical architecture} where a diffusion model predicts the trocar-invariant component and a deterministic MLP completes the trocar-dependent component.

We summarize our contributions:
\begin{enumerate}
    \item We formalize \textbf{trocar-adaptive surgical manipulation} for standard 6-DoF manipulators with fixed external cameras.
    \item We propose four \textbf{RCM-aware action space parameterizations} guaranteeing constraint satisfaction by construction.
    \item We introduce \textbf{trocar-centric spatial encoding} for observation space design.
    \item We present \textbf{single and hierarchical architectures} tailored to each action space category.
\end{enumerate}

%==============================================================================
% SECTION 2: RELATED WORK
%==============================================================================
\section{Related Work}
\label{sec:related_work}

\subsection{Learning-based Surgical Automation}

Machine learning applications to surgical robotics span perception, planning, and control. Early work focused on learning from demonstrations for surgical subtasks \cite{van2010superhuman, schulman2013case}. Recent approaches leverage deep learning for end-to-end visuomotor policies. SurRoL \cite{xu2021surrol} provides a simulation platform for surgical RL, while ORBIT-Surgical \cite{yu2024orbit} extends this to GPU-accelerated simulation.

Imitation learning has emerged as the dominant paradigm. Diffusion Policy \cite{chi2023diffusion} advanced the state-of-the-art by capturing multimodal action distributions through denoising diffusion models.

\textbf{Handling Trocar Variation.} Recent works on generative policies for surgery—SRT \cite{kim2024srt}, SRT-H \cite{kim2024srth}, and SutureBot \cite{chiu2024suturebot}—have addressed varying trocar configurations. However, these approaches:
\begin{itemize}
    \item Use \textbf{wrist-mounted cameras} to implicitly infer trocar frame information from visual observations, rather than explicitly conditioning on trocar parameters.
    \item Employ \textbf{relative pose actions} without constraining outputs to the RCM-feasible manifold.
    \item Rely on low-level controllers to \textbf{project infeasible commands} onto valid motions, which can introduce tracking errors and discontinuities.
\end{itemize}

In contrast, \textbf{STAR-Diff explicitly parameterizes the RCM constraint manifold}, guaranteeing that every policy output is feasible by construction. We also demonstrate that explicit trocar conditioning with a fixed external camera can achieve robust generalization without wrist-mounted sensing.

\subsection{Remote Center of Motion Constraints}

The RCM constraint ensures instrument motion does not traumatize tissue at the insertion point. \textbf{Hardware-based} solutions use specialized kinematic designs \cite{guthart2000intuitive, taylor1999steady}. \textbf{Software-based} approaches employ constrained optimization \cite{sandoval2017collaborative} or control barrier functions \cite{selvaggio2018safe}—but these add computational overhead and may introduce tracking errors when projecting infeasible commands. \textbf{Learning-based} methods incorporate RCM as penalty terms \cite{lu2021super}, but penalties do not guarantee constraint satisfaction. 

Our approach differs fundamentally: by parameterizing the RCM manifold directly as the action space, \textbf{constraint satisfaction is guaranteed by construction}, eliminating the need for runtime projection.

\subsection{Spatial Encoding for Visuomotor Learning}

Bridging observation and action coordinate frames is a key challenge. Point cloud observations \cite{ze20243d} provide 3D information. Neural descriptor fields \cite{simeonov2022neural} learn SE(3)-equivariant representations. Coordinate convolutions \cite{liu2018intriguing} append pixel coordinates as input channels. \textbf{We construct dense trocar-frame coordinate maps that embed geometric priors about the RCM constraint.}

\subsection{Diffusion Models for Robot Control}

Diffusion models \cite{ho2020denoising} have entered robotics through Diffusion Policy \cite{chi2023diffusion}. Extensions include 3D Diffusion Policy \cite{ze20243d} and Consistency Policy \cite{prasad2024consistency}. Our work adapts diffusion to surgical constraints through RCM-aware action spaces and trocar-centric observations.

%==============================================================================
% SECTION 3: PROBLEM FORMULATION
%==============================================================================
\section{Problem Formulation}
\label{sec:problem_formulation}

\subsection{Coordinate Frames}

We establish the following coordinate frames (Fig.~\ref{fig:frames}):
\begin{itemize}
    \item $\{W\}$: World frame, fixed.
    \item $\{C\}$: Camera frame, fixed relative to $\{W\}$ with known transform ${}^{W}T_{C} \in \SE(3)$.
    \item $\{T\}$: Trocar frame, centered at the trocar point $\ptrocar \in \real^3$. The transform ${}^{W}T_{T}(\lambdatrocar) \in \SE(3)$ depends on trocar parameters.
    \item $\{E\}$: End-effector frame, at the jaw center of the laparoscopic grasper.
\end{itemize}

\subsection{Trocar Parameterization}

We parameterize trocar position using spherical coordinates centered at a reference point $\mathbf{o}_{\text{ref}}$:
\begin{equation}
    \lambdatrocar = (r, \theta, \phi) \in \real^{+} \times [0, \pi] \times [0, 2\pi),
    \label{eq:trocar_param}
\end{equation}
where $r$ is radial distance, $\theta$ is polar angle, and $\phi$ is azimuthal angle. The trocar position in world coordinates is:
\begin{equation}
    \ptrocar(\lambdatrocar) = \mathbf{o}_{\text{ref}} + r \begin{bmatrix} \sin\theta \cos\phi \\ \sin\theta \sin\phi \\ \cos\theta \end{bmatrix}.
    \label{eq:trocar_position}
\end{equation}

\subsection{The RCM Constraint Manifold}

\begin{definition}[Remote Center of Motion]
A manipulator satisfies the RCM constraint at point $\ptrocar$ if the instrument's longitudinal axis always passes through $\ptrocar$:
\begin{equation}
    \mathbf{p}_E = \ptrocar + d \cdot R_E \mathbf{e}_z, \quad d \in \real,
    \label{eq:rcm_constraint}
\end{equation}
where $R_E \in \SO(3)$ and $\mathbf{p}_E \in \real^3$ are end-effector orientation and position, $\mathbf{e}_z = [0, 0, 1]^\top$ is the instrument's longitudinal axis, and $d$ is insertion depth.
\end{definition}

\begin{proposition}[RCM Manifold Structure]
The set of poses satisfying the RCM constraint forms a 4-dimensional submanifold $\Mrcm(\lambdatrocar) \subset \SE(3)$, diffeomorphic to $S^2 \times S^1 \times \real$, corresponding to instrument direction (2 DoF), axial rotation (1 DoF), and insertion depth (1 DoF).
\end{proposition}

\subsection{Problem Statement}

\textbf{Given:}
\begin{itemize}
    \item A dataset $\mathcal{D} = \{(\tau_i, \lambda_i)\}_{i=1}^N$ of expert demonstrations under various trocar configurations.
    \item A distribution $p(\lambdatrocar)$ over trocar configurations.
\end{itemize}

\textbf{Find:} A policy $\pi(a \mid o, \lambdatrocar)$ that:
\begin{enumerate}
    \item Maximizes task success across $p(\lambdatrocar)$, including unseen configurations.
    \item Guarantees RCM constraint satisfaction by construction.
    \item Enables efficient real-time inference.
\end{enumerate}

%==============================================================================
% SECTION 4: METHODOLOGY
%==============================================================================
\section{Methodology}
\label{sec:methodology}

We present STAR-Diff, a diffusion-based framework for trocar-adaptive surgical manipulation. Our methodology centers on two design pillars: \textbf{RCM-aware action space} and \textbf{trocar-centric observation space}, with architecture choices tailored to each action space category.

\subsection{Overview}

STAR-Diff consists of three components (Fig.~\ref{fig:architecture}):
\begin{enumerate}
    \item \textbf{RCM-aware Action Space}: Four parameterizations of the RCM constraint manifold, categorized as fully-relative or mixed.
    \item \textbf{Trocar-Centric Observation Space}: RGB images augmented with dense trocar-frame coordinate maps.
    \item \textbf{Policy Architecture}: Single model for fully-relative; hierarchical model for mixed action spaces.
\end{enumerate}

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/architecture.pdf}
    \caption{\textbf{STAR-Diff Architecture.} (Left) Single architecture for fully-relative action spaces. (Right) Hierarchical architecture for mixed action spaces.}
    \label{fig:architecture}
\end{figure}

\subsection{RCM-aware Action Space Design}
\label{subsec:action_space}

We directly parameterize the action space using the RCM constraint manifold. We identify four candidate parameterizations:

\begin{equation}
\boxed{
\begin{aligned}
    &\textbf{Fully-Relative:} \\
    &\quad \xrcm^{(1)} = (d_{\text{rel}}, R_{\text{rel}}) & & \text{[Depth, Rotation]} \\
    &\quad \xrcm^{(2)} = (\gamrel, \prel) & & \text{[Roll, Position]} \\[0.5em]
    &\textbf{Mixed (Relative, Absolute):} \\
    &\quad \xrcm^{(3)} = (d_{\text{rel}}, R_{\text{abs}}) & & \text{[Depth, Rotation]} \\
    &\quad \xrcm^{(4)} = (\gamrel, \pabs) & & \text{[Roll, Position]}
\end{aligned}
}
\label{eq:rcm_parameterizations}
\end{equation}

``Relative'' quantities are in the trocar frame $\{T\}$; ``absolute'' quantities are in the world frame $\{W\}$.

\subsubsection{Fully-Relative Parameterizations}

\textbf{$\xrcm^{(1)} = (d_{\text{rel}}, R_{\text{rel}})$}: Insertion depth and rotation in the trocar frame.

\textbf{$\xrcm^{(2)} = (\gamrel, \prel)$}: Axial roll and position in the trocar frame.

Both components are trocar-dependent: the same task state corresponds to different action values for different trocar placements.

\subsubsection{Mixed Parameterizations}

\textbf{$\xrcm^{(3)} = (d_{\text{rel}}, R_{\text{abs}})$}: Relative depth with absolute rotation.

\textbf{$\xrcm^{(4)} = (\gamrel, \pabs)$}: Relative roll with absolute position.

Mixed parameterizations contain one \textbf{trocar-invariant} component (absolute) and one \textbf{trocar-dependent} component (relative).

\begin{table}[t]
    \centering
    \caption{Properties of RCM Action Space Parameterizations}
    \label{tab:rcm_comparison}
    \begin{tabular}{@{}lcccc@{}}
        \toprule
        & $\xrcm^{(1)}$ & $\xrcm^{(2)}$ & $\xrcm^{(3)}$ & $\xrcm^{(4)}$ \\
        \midrule
        Category & \multicolumn{2}{c}{Fully-Relative} & \multicolumn{2}{c}{Mixed} \\
        Trocar-invariant & \xmark & \xmark & $R_{\text{abs}}$ & $\pabs$ \\
        Config. consistency & -- & -- & Poor & Good \\
        Architecture & Single & Single & Hier. & Hier. \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{Trocar-Invariance Analysis}

\begin{proposition}[Trocar-Invariance of Absolute Position]
\label{prop:invariance}
For visual servoing tasks where the target is defined by visual features in a fixed camera frame, the desired absolute position $\pabs^*$ is independent of trocar parameters $\lambdatrocar$.
\end{proposition}

$\xrcm^{(3)}$ exhibits \textbf{configuration inconsistency}: the same absolute rotation corresponds to different physical configurations depending on $\lambdatrocar$. $\xrcm^{(4)}$ exhibits \textbf{configuration consistency}: the same $\pabs$ corresponds to similar tip positions regardless of trocar placement.

\subsubsection{RCM Constraint Guarantee}

\begin{theorem}[RCM Compliance by Construction]
Any action produced using $\xrcm^{(1)}$--$\xrcm^{(4)}$, when converted to an end-effector pose via the transformations in Appendix~\ref{app:action_transform}, satisfies the RCM constraint \eqref{eq:rcm_constraint}.
\end{theorem}

This guarantee is \textit{unconditional}: regardless of neural network outputs, the resulting pose always satisfies RCM. No runtime projection is needed.

\subsection{Trocar-Centric Observation Space Design}
\label{subsec:observation_space}

We address the observation-action frame mismatch through trocar-centric spatial encoding.

\subsubsection{Trocar Parameter Conditioning}

The trocar configuration $\lambdatrocar = (r, \theta, \phi)$ is explicitly provided:
\begin{equation}
    \mathbf{e}_\lambda = \text{MLP}_{\text{embed}}(\lambdatrocar) \in \real^{d_\lambda}.
\end{equation}

\subsubsection{Dense Trocar-Frame Coordinate Maps}

We augment RGB observations with per-pixel 3D coordinates in the trocar frame.

\textbf{Step 1: 2D-to-3D Lifting.} Project each pixel to camera-frame coordinates:
\begin{equation}
    \Pcam(u, v) = Z(u, v) \cdot K^{-1} \begin{bmatrix} u \\ v \\ 1 \end{bmatrix}.
\end{equation}

\textbf{Step 2: Trocar-Centric Transformation.}
\begin{equation}
    \Ptro(u, v) = R_{T \leftarrow C} \cdot \Pcam(u, v) + t_{T \leftarrow C}.
\end{equation}

\textbf{Step 3: Augmented Observation.}
\begin{equation}
    \mathbf{O}_{\text{aug}} = \text{Concat}(\mathbf{I}_{\text{RGB}}, \Ptro^{\text{norm}}) \in \real^{H \times W \times 6}.
    \label{eq:augmented_obs}
\end{equation}

\subsection{Policy Architecture}
\label{subsec:architecture}

\subsubsection{Single Architecture for Fully-Relative Action Spaces}

For $\xrcm^{(1)}$ and $\xrcm^{(2)}$, a single diffusion model predicts the complete action:
\begin{equation}
    \pi_{\text{single}}: (\mathbf{O}_{\text{aug}}, \mathbf{x}_{\text{history}}, \lambdatrocar) \mapsto \xrcm^{(k)}, \quad k \in \{1, 2\}
\end{equation}

\subsubsection{Hierarchical Architecture for Mixed Action Spaces}

For $\xrcm^{(3)}$ and $\xrcm^{(4)}$, we use a two-stage hierarchical architecture:

\textbf{Stage 1: Absolute Component (Diffusion Model)}
\begin{equation}
    \pi_{\text{abs}}: (\mathbf{O}_{\text{aug}}, \mathbf{x}_{\text{abs}}^{\text{history}}) \mapsto \mathbf{x}_{\text{abs}}^{t+1:t+H}
\end{equation}
Trocar parameters are \textbf{not conditioned} since the absolute component is trocar-invariant.

\textbf{Stage 2: Relative Component (Deterministic MLP)}
\begin{equation}
    f_{\text{rel}}: (\mathbf{O}_{\text{aug}}, \mathbf{x}_{\text{abs}}^{t+1:t+H}, \mathbf{x}_{\text{rel}}^{\text{history}}, \lambdatrocar) \mapsto \mathbf{x}_{\text{rel}}^{t+1:t+H}
\end{equation}

\subsection{Diffusion Policy Details}

We adopt DDPM \cite{ho2020denoising}. The noise prediction network $\epsilon_\theta$ is trained with:
\begin{equation}
    \mathcal{L}_{\text{diff}} = \mathbb{E}_{\mathbf{a}_0, k, \bm{\epsilon}} \left[ \| \bm{\epsilon} - \epsilon_\theta(\mathbf{a}_k, \mathbf{c}, k) \|^2 \right].
\end{equation}

For hierarchical architectures, the MLP is trained with:
\begin{equation}
    \mathcal{L}_{\text{rel}} = \mathbb{E} \left[ \| \mathbf{x}_{\text{rel}}^{t+1:t+H} - f_{\text{rel}}(\cdot) \|^2 \right].
\end{equation}

Total loss: $\mathcal{L} = \mathcal{L}_{\text{diff}} + \lambda \mathcal{L}_{\text{rel}}$ with $\lambda = 0.1$.

\subsection{Action Execution via Low-Level Control}
\label{subsec:action_execution}

\subsubsection{Action-to-Pose Transformation}

All four parameterizations are converted to $\SE(3)$ poses via $\mathcal{T}: \xrcm^{(k)} \times \lambdatrocar \rightarrow \SE(3)$ (Appendix~\ref{app:action_transform}).

\subsubsection{Low-Level Control}

Given desired pose $(R_E^*, \mathbf{p}_E^*)$:
\begin{enumerate}
    \item \textbf{Inverse Kinematics}: $\mathbf{q}^* = \text{IK}(R_E^*, \mathbf{p}_E^*; \mathbf{q}_{\text{current}})$
    \item \textbf{Joint Space Controller}: $\bm{\tau} = K_p (\mathbf{q}^* - \mathbf{q}) + K_d (\dot{\mathbf{q}}^* - \dot{\mathbf{q}})$
\end{enumerate}

Since all policy outputs lie on the RCM manifold by construction, no projection or clamping is required.

%==============================================================================
% SECTION 5: EXPERIMENTS
%==============================================================================
\section{Experiments}
\label{sec:experiments}

We design experiments to evaluate:
\begin{itemize}
    \item \textbf{RQ1}: Generalization to unseen trocar positions
    \item \textbf{RQ2}: Comparison of RCM action space parameterizations
    \item \textbf{RQ3}: Effect of trocar-centric spatial encoding
    \item \textbf{RQ4}: Single vs. hierarchical architecture for mixed action spaces
\end{itemize}

\subsection{Experimental Setup}

\subsubsection{Task}

We evaluate on \textbf{Peg Transfer} from the FLS benchmark \cite{peters2004development}, implemented in SurRoL \cite{xu2021surrol} simulation with a 6-DoF Fairino FR5 and laparoscopic grasper, observed by a fixed RGB-D camera.

\subsubsection{Trocar Configuration}

12 trocar configurations total:
\begin{itemize}
    \item \textbf{Training}: 8 configurations (67\%)
    \item \textbf{Test (Seen)}: Same 8 as training
    \item \textbf{Test (Unseen)}: 4 held-out configurations (33\%)
\end{itemize}

\subsubsection{Metrics}

\textbf{Task Success Rate (SR)}: Percentage of successful transfers within 60 seconds (30 trials per configuration).

\textbf{Generalization Gap}: $\Delta_{\text{gen}} = \text{SR}_{\text{seen}} - \text{SR}_{\text{unseen}}$.

\subsection{Methods}

\begin{table}[t]
    \centering
    \caption{Compared Methods}
    \label{tab:methods}
    \resizebox{\columnwidth}{!}{
    \begin{tabular}{@{}llccc@{}}
        \toprule
        \textbf{Group} & \textbf{Method} & \textbf{Action Space} & \textbf{Obs.} & \textbf{Arch.} \\
        \midrule
        \multirow{2}{*}{\textit{Baselines}} 
        & DP-SE3 & $\SE(3)$ & RGB & Single \\
        & DP-SE3-Proj & $\SE(3)$ + Proj & RGB & Single \\
        \midrule
        \multirow{2}{*}{\textit{Fully-Rel.}} 
        & STAR-1 & $\xrcm^{(1)}$ & RGB+TC & Single \\
        & STAR-2 & $\xrcm^{(2)}$ & RGB+TC & Single \\
        \midrule
        \multirow{4}{*}{\textit{Mixed}} 
        & STAR-3-S & $\xrcm^{(3)}$ & RGB+TC & Single \\
        & STAR-3-H & $\xrcm^{(3)}$ & RGB+TC & Hier. \\
        & STAR-4-S & $\xrcm^{(4)}$ & RGB+TC & Single \\
        & STAR-4-H & $\xrcm^{(4)}$ & RGB+TC & Hier. \\
        \bottomrule
    \end{tabular}
    }
    \vspace{0.3em}
    
    {\footnotesize TC: Trocar-centric coordinates. S: Single. H: Hierarchical.}
\end{table}

\textbf{Baselines}: DP-SE3 (Diffusion Policy in $\SE(3)$) and DP-SE3-Proj (with post-hoc RCM projection).

\textbf{Fully-Relative}: STAR-1 ($\xrcm^{(1)}$) and STAR-2 ($\xrcm^{(2)}$) with single architecture.

\textbf{Mixed}: STAR-3-S/H ($\xrcm^{(3)}$) and STAR-4-S/H ($\xrcm^{(4)}$) with single and hierarchical architectures.

\subsection{Main Results}

\begin{table}[t]
    \centering
    \caption{Task Success Rate (\%) on Peg Transfer}
    \label{tab:main_results}
    \resizebox{\columnwidth}{!}{
    \begin{tabular}{@{}llccc@{}}
        \toprule
        \textbf{Group} & \textbf{Method} & \textbf{Seen}$\uparrow$ & \textbf{Unseen}$\uparrow$ & $\Delta_{\text{gen}}$$\downarrow$ \\
        \midrule
        \multirow{2}{*}{\textit{Baselines}} 
        & DP-SE3 & \texttt{[XX.X]} & \texttt{[XX.X]} & \texttt{[XX.X]} \\
        & DP-SE3-Proj & \texttt{[XX.X]} & \texttt{[XX.X]} & \texttt{[XX.X]} \\
        \midrule
        \multirow{2}{*}{\textit{Fully-Rel.}} 
        & STAR-1 & \texttt{[XX.X]} & \texttt{[XX.X]} & \texttt{[XX.X]} \\
        & STAR-2 & \texttt{[XX.X]} & \texttt{[XX.X]} & \texttt{[XX.X]} \\
        \midrule
        \multirow{4}{*}{\textit{Mixed}} 
        & STAR-3-S & \texttt{[XX.X]} & \texttt{[XX.X]} & \texttt{[XX.X]} \\
        & STAR-3-H & \texttt{[XX.X]} & \texttt{[XX.X]} & \texttt{[XX.X]} \\
        & STAR-4-S & \texttt{[XX.X]} & \texttt{[XX.X]} & \texttt{[XX.X]} \\
        & STAR-4-H & \texttt{[XX.X]} & \texttt{[XX.X]} & \texttt{[XX.X]} \\
        \bottomrule
    \end{tabular}
    }
\end{table}

\subsection{Ablation: Observation Space}

\begin{table}[t]
    \centering
    \caption{Effect of Trocar-Centric Encoding (using STAR-4-H)}
    \label{tab:obs_ablation}
    \begin{tabular}{@{}lccc@{}}
        \toprule
        \textbf{Observation} & \textbf{Seen} & \textbf{Unseen} & $\Delta_{\text{gen}}$ \\
        \midrule
        RGB only & \texttt{[XX.X]} & \texttt{[XX.X]} & \texttt{[XX.X]} \\
        RGB + TC & \texttt{[XX.X]} & \texttt{[XX.X]} & \texttt{[XX.X]} \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Ablation: Architecture (Single vs. Hierarchical)}

Comparison of STAR-3-S vs. STAR-3-H and STAR-4-S vs. STAR-4-H in Table~\ref{tab:main_results} evaluates the benefit of hierarchical decomposition for mixed action spaces.

%==============================================================================
% SECTION 6: DISCUSSION AND CONCLUSION
%==============================================================================
\section{Discussion and Conclusion}
\label{sec:conclusion}

\subsection{Limitations}

\textit{(1) Depth Requirement}: Trocar-centric encoding requires depth; extending to monocular depth estimation would broaden applicability.

\textit{(2) 6-DoF Constraint}: Extension to redundant manipulators (7+ DoF) is future work.

\textit{(3) Fixed Camera}: Incorporating dynamic endoscope poses would enhance clinical applicability.

\textit{(4) Simulation-Only}: Hardware validation is needed.

\subsection{Conclusion}

We presented STAR-Diff for trocar-adaptive surgical manipulation with the following contributions:

\begin{enumerate}
    \item \textbf{RCM-aware Action Space}: Four parameterizations guaranteeing constraint satisfaction by construction—eliminating the need for runtime projection that plagues existing approaches.
    
    \item \textbf{Trocar-Centric Observation Space}: Dense coordinate encoding bridging observation-action frame gaps without wrist-mounted cameras.
    
    \item \textbf{Tailored Architectures}: Single model for fully-relative; hierarchical model for mixed action spaces.
\end{enumerate}

%==============================================================================
% APPENDIX
%==============================================================================
\appendix

\section{Action-to-Pose Transformations}
\label{app:action_transform}

\subsection{Preliminaries}

Trocar position: $\ptrocar = \mathbf{o}_{\text{ref}} + r [\sin\theta \cos\phi, \sin\theta \sin\phi, \cos\theta]^\top$

$\text{RotationAlign}(\mathbf{a}, \mathbf{b})$ computes rotation mapping $\mathbf{a}$ to $\mathbf{b}$ via Rodrigues' formula.

\subsection{$\xrcm^{(1)} = (d_{\text{rel}}, R_{\text{rel}})$}
\begin{align}
    R_E &= {}^{W}R_{T}(\lambdatrocar) \cdot R_{\text{rel}} \\
    \mathbf{p}_E &= \ptrocar + d_{\text{rel}} \cdot R_E \mathbf{e}_z
\end{align}

\subsection{$\xrcm^{(2)} = (\gamrel, \prel)$}
\begin{align}
    \mathbf{p}_E &= {}^{W}R_{T} \cdot \prel + \ptrocar \\
    \mathbf{v} &= (\mathbf{p}_E - \ptrocar) / \|\mathbf{p}_E - \ptrocar\| \\
    R_E &= \text{RotationAlign}(\mathbf{e}_z, \mathbf{v}) \cdot R_z(\gamrel)
\end{align}

\subsection{$\xrcm^{(3)} = (d_{\text{rel}}, R_{\text{abs}})$}
\begin{align}
    R_E &= R_{\text{abs}} \\
    \mathbf{p}_E &= \ptrocar + d_{\text{rel}} \cdot R_E \mathbf{e}_z
\end{align}

\subsection{$\xrcm^{(4)} = (\gamrel, \pabs)$}
\begin{align}
    \mathbf{p}_E &= \pabs \\
    \mathbf{v} &= (\pabs - \ptrocar) / \|\pabs - \ptrocar\| \\
    R_E &= \text{RotationAlign}(\mathbf{e}_z, \mathbf{v}) \cdot R_z(\gamrel)
\end{align}

\section{Network Architecture}
\label{app:network}

\textbf{Vision Encoder}: ResNet-18 (6-channel) with spatial softmax, output $\in \real^{512}$.

\textbf{Trocar Encoder}: 2-layer MLP, output $\in \real^{64}$.

\textbf{U-Net}: 1D with 4 blocks, 256 base channels, FiLM conditioning.

\textbf{Relative MLP}: 3 residual blocks (256 dim, LayerNorm, GELU).

\section{Training Details}
\label{app:training}

\textbf{Data}: 30 demos per trocar config at 30 Hz. Trocar range: $r \in [0, 5]$ cm, $\theta \in [60°, 120°]$, $\phi \in [0°, 360°]$.

\textbf{Diffusion}: $K = 100$ train / 10 DDIM inference, cosine schedule, $T_o = 2$, $H = 16$.

\textbf{Optimization}: AdamW, lr $= 10^{-4}$, batch 256, 100K iterations.

%==============================================================================
% REFERENCES
%==============================================================================
\bibliographystyle{IEEEtran}
\begin{thebibliography}{99}

\bibitem{mack2001minimally}
M. J. Mack, ``Minimally invasive and robotic surgery,'' \textit{JAMA}, vol. 285, no. 5, pp. 568--572, 2001.

\bibitem{intuitive2023davinci}
Intuitive Surgical, ``da Vinci Surgical System,'' 2023.

\bibitem{chi2023diffusion}
C. Chi \textit{et al.}, ``Diffusion policy: Visuomotor policy learning via action diffusion,'' in \textit{Proc. RSS}, 2023.

\bibitem{zhao2023learning}
T. Z. Zhao \textit{et al.}, ``Learning fine-grained bimanual manipulation with low-cost hardware,'' in \textit{Proc. RSS}, 2023.

\bibitem{scheikl2024movement}
S. Scheikl \textit{et al.}, ``Movement primitive diffusion for dexterous surgical manipulation,'' in \textit{Proc. ICRA}, 2024.

\bibitem{xu2021surrol}
J. Xu \textit{et al.}, ``SurRoL: An open-source reinforcement learning centered and dVRK compatible platform for surgical robot learning,'' in \textit{Proc. IROS}, 2021.

\bibitem{reynolds2001practical}
W. Reynolds, ``The first laparoscopic cholecystectomy,'' \textit{JSLS}, vol. 5, no. 1, pp. 89--94, 2001.

\bibitem{murphy2001surgeon}
D. Murphy \textit{et al.}, ``Surgeon preferences and peritoneal access,'' \textit{Surg. Endosc.}, vol. 15, pp. 1236--1240, 2001.

\bibitem{kazanzides2014open}
P. Kazanzides \textit{et al.}, ``An open-source research kit for the da Vinci surgical system,'' in \textit{Proc. ICRA}, 2014.

\bibitem{kim2024srt}
J. Kim \textit{et al.}, ``Surgical Robot Transformer (SRT): Imitation learning for surgical tasks,'' in \textit{Proc. ICRA}, 2024.

\bibitem{kim2024srth}
J. Kim \textit{et al.}, ``SRT-H: A hierarchical framework for autonomous surgery via language conditioned imitation learning,'' \textit{arXiv preprint}, 2024.

\bibitem{chiu2024suturebot}
A. Chiu \textit{et al.}, ``SutureBot: A precision framework and benchmark for autonomous end-to-end suturing,'' \textit{arXiv preprint}, 2024.

\bibitem{taylor1999steady}
R. H. Taylor \textit{et al.}, ``A steady-hand robotic system for microsurgical augmentation,'' \textit{Int. J. Robot. Res.}, vol. 18, no. 12, pp. 1201--1210, 1999.

\bibitem{sandoval2017collaborative}
J. Sandoval \textit{et al.}, ``Collaborative framework for robot-assisted minimally invasive surgery,'' in \textit{Proc. ICRA}, 2017.

\bibitem{lu2021super}
J. Lu \textit{et al.}, ``Super: A surgical perception framework for endoscopic tissue manipulation,'' \textit{IEEE RA-L}, vol. 6, no. 2, pp. 3977--3984, 2021.

\bibitem{yu2024orbit}
Y. Yu \textit{et al.}, ``ORBIT-Surgical: An open-simulation framework for learning surgical augmented dexterity,'' in \textit{Proc. ICRA}, 2024.

\bibitem{van2010superhuman}
J. van den Berg \textit{et al.}, ``Superhuman performance of surgical tasks by robots using iterative learning,'' in \textit{Proc. ICRA}, 2010.

\bibitem{schulman2013case}
J. Schulman \textit{et al.}, ``A case study of trajectory transfer through non-rigid registration for a simplified suturing scenario,'' in \textit{Proc. IROS}, 2013.

\bibitem{guthart2000intuitive}
G. S. Guthart and J. K. Salisbury, ``The Intuitive telesurgery system: Overview and application,'' in \textit{Proc. ICRA}, 2000.

\bibitem{selvaggio2018safe}
M. Selvaggio \textit{et al.}, ``Safe and efficient autonomous navigation for teleoperation in surgery,'' \textit{IEEE RA-L}, vol. 3, no. 4, pp. 3373--3380, 2018.

\bibitem{ze20243d}
Y. Ze \textit{et al.}, ``3D diffusion policy,'' in \textit{Proc. RSS}, 2024.

\bibitem{simeonov2022neural}
A. Simeonov \textit{et al.}, ``Neural descriptor fields: SE(3)-equivariant object representations for manipulation,'' in \textit{Proc. ICRA}, 2022.

\bibitem{liu2018intriguing}
R. Liu \textit{et al.}, ``An intriguing failing of convolutional neural networks and the coordconv solution,'' in \textit{Proc. NeurIPS}, 2018.

\bibitem{ho2020denoising}
J. Ho, A. Jain, and P. Abbeel, ``Denoising diffusion probabilistic models,'' in \textit{Proc. NeurIPS}, 2020.

\bibitem{prasad2024consistency}
V. Prasad \textit{et al.}, ``Consistency policy: Accelerated visuomotor policies via consistency distillation,'' in \textit{Proc. RSS}, 2024.

\bibitem{peters2004development}
J. H. Peters \textit{et al.}, ``Development and validation of a comprehensive program of education and assessment of the basic fundamentals of laparoscopic surgery,'' \textit{Surgery}, vol. 135, no. 1, pp. 21--27, 2004.

\end{thebibliography}

\end{document}