\documentclass[letterpaper, 10pt, conference]{ieeeconf}

% Packages
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{bm}
\usepackage{mathtools}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning,calc}

% Custom commands
\newcommand{\real}{\mathbb{R}}
\newcommand{\SE}{\mathrm{SE}}
\newcommand{\SO}{\mathrm{SO}}
\newcommand{\pabs}{\mathbf{p}_{\text{abs}}}
\newcommand{\prel}{\mathbf{p}_{\text{rel}}}
\newcommand{\ptrocar}{\mathbf{p}_{T}}
\newcommand{\lambdatrocar}{\lambda_{\text{trocar}}}
\newcommand{\gamrel}{\gamma_{\text{rel}}}
\newcommand{\xrcm}{x_{\text{RCM}}}
\newcommand{\Mrcm}{\mathcal{M}_{\text{RCM}}}

\title{\LARGE \bf STAR-Diff: Surgical Trocar-Adaptive Diffusion Policy \\ with RCM-aware Action Space}

\author{Anonymous Authors}

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%==============================================================================
% ABSTRACT
%==============================================================================
\begin{abstract}
Automating laparoscopic surgery holds significant promise for improving surgical outcomes, yet existing learning-based approaches assume fixed trocar positions during both training and deployment—a simplification that rarely holds in clinical practice. We present \textbf{STAR-Diff} (\textbf{S}urgical \textbf{T}rocar-\textbf{A}daptive, \textbf{R}CM-aware \textbf{Diff}usion Policy), a novel imitation learning framework that enables generalization across varying trocar placements without retraining. Our key insight is that the Remote Center of Motion (RCM) constraint, which restricts instrument motion to pass through the trocar point, defines a 4-dimensional submanifold of $\SE(3)$. By directly parameterizing this constraint manifold as the action space, we eliminate the need for post-hoc constraint enforcement. Furthermore, we observe that the absolute end-effector position in the camera frame is trocar-invariant for visual servoing tasks, motivating a hierarchical architecture that decouples trocar-invariant position prediction (via diffusion) from trocar-dependent axial rotation estimation (via deterministic mapping). Designed for standard 6-DoF manipulators without specialized surgical wrists, STAR-Diff democratizes surgical automation beyond proprietary platforms. We validate our approach on multiple surgical tasks, demonstrating substantial improvements in generalization to unseen trocar configurations while maintaining near-zero RCM constraint violations.
\end{abstract}

%==============================================================================
% SECTION 1: INTRODUCTION
%==============================================================================
\section{Introduction}
\label{sec:introduction}

Minimally invasive surgery (MIS), particularly laparoscopic procedures, has revolutionized surgical practice by reducing patient trauma, hospital stays, and recovery times \cite{mack2001minimally}. However, the inherent challenges of operating through small incisions—limited field of view, reduced haptic feedback, and constrained instrument motion—place significant cognitive and physical demands on surgeons. Robot-assisted surgical systems, exemplified by the da Vinci platform \cite{intuitive2023davinci}, have emerged as transformative tools that enhance precision and ergonomics. Yet, the potential for autonomous execution of surgical subtasks remains largely unrealized in clinical settings.

Recent advances in robot learning, particularly imitation learning and diffusion-based policies \cite{chi2023diffusion, zhao2023learning}, have demonstrated remarkable success in contact-rich manipulation tasks. Several works have applied these techniques to surgical automation \cite{scheikl2024movement, xu2021surrol}, achieving impressive results on benchmark tasks such as peg transfer, tissue manipulation, and suturing. However, a critical assumption pervades nearly all existing work: \textit{the trocar position is fixed and known a priori during both training and deployment}.

This assumption fundamentally limits the practical applicability of learned surgical policies. In clinical practice, trocar placement varies substantially based on:
\begin{itemize}
    \item \textbf{Patient anatomy}: Body habitus, organ size, and pathology location necessitate patient-specific port configurations \cite{reynolds2001practical}.
    \item \textbf{Procedure type}: Different surgical procedures (cholecystectomy, appendectomy, hernia repair) require distinct trocar arrangements optimized for target anatomy access.
    \item \textbf{Surgeon preference}: Individual surgeons develop personalized ergonomic preferences for port placement \cite{murphy2001surgeon}.
\end{itemize}

When deployed in a trocar configuration different from training, existing policies face two failure modes: (1) \textbf{workspace mismatch}, where the learned end-effector trajectories become unreachable or kinematically infeasible, and (2) \textbf{RCM constraint violation}, where the instrument axis fails to pass through the trocar point, risking tissue damage at the incision site.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/teaser.pdf}
    \caption{\textbf{Problem Overview.} (a) Existing surgical policies are trained and deployed with a fixed trocar position, failing when trocar placement varies. (b) STAR-Diff learns a single policy that adapts to arbitrary trocar positions by leveraging an RCM-aware action space and hierarchical architecture that decouples trocar-invariant from trocar-dependent components.}
    \label{fig:teaser}
\end{figure}

The Remote Center of Motion (RCM) constraint is the defining kinematic characteristic of laparoscopic surgery. It requires that the instrument's longitudinal axis always passes through the trocar point, effectively reducing the instrument's degrees of freedom from 6 to 4 (excluding gripper actuation). Prior work has addressed RCM compliance through various mechanisms: hardware-based solutions using specialized kinematic designs \cite{taylor1999steady}, software-based approaches using constrained optimization \cite{sandoval2017collaborative}, and learning-based methods that incorporate RCM as a loss term \cite{lu2021super}. However, these approaches either require specialized hardware, introduce computational overhead at inference time, or fail to guarantee strict constraint satisfaction.

In this work, we propose \textbf{STAR-Diff}, a diffusion-based imitation learning framework that achieves trocar-adaptive surgical manipulation through two key innovations:

\textbf{(1) RCM-aware Action Space.} Rather than learning in the ambient $\SE(3)$ space and projecting onto the RCM constraint manifold post-hoc, we directly parameterize the action space as the 4-dimensional RCM constraint manifold $\Mrcm$. This ``constraint baking'' approach guarantees RCM compliance by construction, eliminating the need for runtime constraint enforcement.

\textbf{(2) Hierarchical Trocar-Adaptive Architecture.} We make a crucial observation: for visual servoing tasks with a fixed camera, the desired end-effector position in world coordinates is \textit{trocar-invariant}—it depends only on the target object's visual appearance, not on where the trocar happens to be placed. This insight motivates a hierarchical decomposition:
\begin{itemize}
    \item A \textbf{diffusion policy} predicts the trocar-invariant absolute position $\pabs$, conditioned only on visual observations.
    \item A \textbf{deterministic network} predicts the trocar-dependent relative rotation $\gamrel$, given the diffusion output and trocar parameters.
\end{itemize}

This decomposition enables the diffusion model to focus on the complex, multimodal distribution of task-relevant positions without being confounded by trocar variation, while the simpler deterministic mapping handles the geometric transformation induced by different trocar placements.

Our framework is designed for standard 6-DoF industrial manipulators (e.g., Fairino FR5) equipped with laparoscopic graspers, deliberately avoiding dependence on proprietary systems with specialized wrists (e.g., da Vinci EndoWrist). This design choice serves two purposes: (1) it \textit{democratizes} surgical automation research by enabling experimentation with commodity hardware, and (2) it establishes \textit{extensibility} to future systems where surgeons' manual laparoscopic data could be leveraged for policy learning.

We summarize our contributions as follows:
\begin{enumerate}
    \item We formalize the \textbf{trocar-adaptive surgical manipulation} problem and identify the geometric structure of the RCM constraint manifold.
    \item We propose an \textbf{RCM-aware action space} that parameterizes the constraint manifold directly, guaranteeing RCM compliance without post-hoc enforcement.
    \item We introduce a \textbf{hierarchical diffusion architecture} that decouples trocar-invariant position prediction from trocar-dependent rotation estimation.
    \item We demonstrate that STAR-Diff achieves strong generalization to unseen trocar configurations while maintaining near-zero RCM violations on multiple surgical tasks.
\end{enumerate}

%==============================================================================
% SECTION 2: RELATED WORK
%==============================================================================
\section{Related Work}
\label{sec:related_work}

\subsection{Learning-based Surgical Automation}

The application of machine learning to surgical robotics has grown substantially, spanning perception, planning, and control. Early work focused on learning from demonstrations (LfD) for isolated surgical subtasks \cite{van2010superhuman, schulman2013case}. More recent approaches leverage deep learning for end-to-end visuomotor policies. Xu et al. \cite{xu2021surrol} introduced SurRoL, a comprehensive simulation platform enabling reinforcement learning for surgical tasks. ORBIT-Surgical \cite{yu2024orbit} extended this to GPU-accelerated simulation with photorealistic rendering. 

Imitation learning has emerged as the dominant paradigm due to the difficulty of reward specification in surgery. Behavior cloning approaches have been applied to tissue manipulation \cite{scheikl2024movement}, surgical cutting \cite{thananjeyan2017multilateral}, and suturing \cite{varier2020collaborative}. The Action Chunking with Transformers (ACT) framework \cite{zhao2023learning} demonstrated that predicting action sequences rather than single actions improves temporal consistency. Diffusion Policy \cite{chi2023diffusion} further advanced the state-of-the-art by leveraging denoising diffusion models to capture multimodal action distributions.

Despite these advances, \textbf{all existing methods assume fixed environmental configurations}, including trocar position. Our work addresses this limitation by explicitly conditioning on trocar parameters and designing an architecture that facilitates generalization.

\subsection{Remote Center of Motion Constraints}

The RCM constraint is fundamental to minimally invasive surgery, ensuring that instrument motion does not traumatize tissue at the insertion point. Solutions broadly fall into three categories:

\textbf{Hardware-based RCM.} Specialized kinematic designs mechanically enforce RCM compliance. The da Vinci system uses a parallelogram mechanism \cite{guthart2000intuitive}, while other designs employ spherical joints \cite{taylor1999steady} or cable-driven architectures \cite{simaan2009design}. These solutions guarantee RCM by construction but require dedicated hardware.

\textbf{Software-based RCM.} For general-purpose manipulators, RCM can be enforced through control. Sandoval et al. \cite{sandoval2017collaborative} formulated RCM as a task-space constraint in a quadratic programming framework. Locke and Patel \cite{locke2007optimal} derived analytical inverse kinematics for RCM-constrained systems. Control barrier functions (CBFs) have been applied to guarantee forward invariance of the RCM constraint set \cite{selvaggio2018safe}. These approaches add computational overhead and may introduce tracking errors.

\textbf{Learning-based RCM.} Recent work incorporates RCM into learning objectives. Lu et al. \cite{lu2021super} added RCM violation as a penalty term during policy optimization. Richter et al. \cite{richter2021open} trained policies with RCM-constrained action spaces but did not address trocar variation. Our approach differs fundamentally: by parameterizing the RCM manifold directly as the action space, \textbf{constraint satisfaction is guaranteed by construction}, not approximated through penalties or projections.

\subsection{Generalization in Robot Learning}

Achieving generalization across environmental variations is a central challenge in robot learning. Domain randomization \cite{tobin2017domain} and domain adaptation \cite{tzeng2020adapting} address visual domain shift. For spatial generalization, SE(3)-equivariant networks \cite{simeonov2022neural} exploit geometric symmetries. Contextual policies condition on task parameters \cite{da2012learning}, while meta-learning approaches \cite{finn2017model} enable rapid adaptation.

In surgical robotics, generalization has received limited attention. Kazanzides et al. \cite{kazanzides2014open} discussed the need for adaptable surgical systems, but learning-based solutions remain scarce. The closest work is that of Shin et al. \cite{shin2019autonomous}, who varied tissue properties but not kinematic configurations. \textbf{To our knowledge, STAR-Diff is the first learning-based approach to explicitly address generalization across trocar positions.}

\subsection{Diffusion Models for Robot Control}

Diffusion models \cite{ho2020denoising, song2020score} have transformed generative modeling and recently entered robotics. Diffusion Policy \cite{chi2023diffusion} demonstrated that framing action prediction as conditional denoising yields policies that capture multimodal behavior and exhibit strong generalization. Follow-up work has applied diffusion to diverse domains: contact-rich manipulation \cite{ze20243d}, locomotion \cite{ajay2022conditional}, and multi-task learning \cite{reuss2023goal}.

Architectural variants have emerged to address specific challenges. Chi et al. \cite{chi2024universal} introduced a universal manipulation interface using diffusion. 3D Diffusion Policy \cite{ze20243d} incorporated point cloud observations for spatial reasoning. Consistency Policy \cite{prasad2024consistency} accelerated inference through distillation. Our work builds on this foundation, adapting the diffusion framework to the unique constraints of surgical manipulation through RCM-aware action spaces and hierarchical decomposition.

%==============================================================================
% SECTION 3: PROBLEM FORMULATION
%==============================================================================
\section{Problem Formulation}
\label{sec:problem_formulation}

\subsection{Notation and Coordinate Frames}

We establish the following coordinate frames (Fig.~\ref{fig:frames}):
\begin{itemize}
    \item $\{S\}$: Space (world) frame, fixed.
    \item $\{C\}$: Camera frame, fixed relative to $\{S\}$ with known transform ${}^{S}T_{C} \in \SE(3)$.
    \item $\{R\}$: Robot base frame, fixed relative to $\{S\}$ with known transform ${}^{S}T_{R} \in \SE(3)$.
    \item $\{T\}$: Trocar frame, centered at the trocar point $\ptrocar \in \real^3$ with $z$-axis aligned to gravity. The transform ${}^{S}T_{T}(\lambdatrocar) \in \SE(3)$ depends on trocar parameters.
    \item $\{E\}$: End-effector (TCP) frame, located at the jaw center of the laparoscopic grasper.
\end{itemize}

We assume a monocular camera observing the surgical workspace, with optical axis directed toward a reference point $\mathbf{o}_{\text{ref}}$ at distance $L$ from the camera center.

\subsection{Trocar Parameterization}

The trocar position varies across procedures. We parameterize it using spherical coordinates centered at the reference point:
\begin{equation}
    \lambdatrocar = (r, \theta, \phi) \in \real^{+} \times [0, \pi] \times [0, 2\pi),
    \label{eq:trocar_param}
\end{equation}
where $r$ is the radial distance from $\mathbf{o}_{\text{ref}}$, $\theta$ is the polar angle, and $\phi$ is the azimuthal angle. The trocar position in world coordinates is:
\begin{equation}
    \ptrocar(\lambdatrocar) = \mathbf{o}_{\text{ref}} + r \begin{bmatrix} \sin\theta \cos\phi \\ \sin\theta \sin\phi \\ \cos\theta \end{bmatrix}.
    \label{eq:trocar_position}
\end{equation}

This parameterization captures clinically relevant trocar variation while providing a compact, continuous representation suitable for conditioning neural networks.

\subsection{The RCM Constraint Manifold}

\begin{definition}[Remote Center of Motion]
A manipulator satisfies the RCM constraint at point $\ptrocar$ if the longitudinal axis of the end-effector always passes through $\ptrocar$. Formally, let $R_E \in \SO(3)$ and $\mathbf{p}_E \in \real^3$ denote the end-effector orientation and position. The RCM constraint requires:
\begin{equation}
    \mathbf{p}_E = \ptrocar + d \cdot R_E \mathbf{e}_z, \quad d \in \real,
    \label{eq:rcm_constraint}
\end{equation}
where $\mathbf{e}_z = [0, 0, 1]^\top$ is the instrument's longitudinal axis in the end-effector frame, and $d$ is the insertion depth (signed).
\end{definition}

\begin{proposition}[RCM Manifold Structure]
The set of end-effector poses satisfying the RCM constraint forms a 4-dimensional submanifold of $\SE(3)$:
\begin{equation}
    \Mrcm(\lambdatrocar) = \{(R_E, \mathbf{p}_E) \in \SE(3) \mid \eqref{eq:rcm_constraint} \text{ holds}\}.
\end{equation}
This manifold is diffeomorphic to $S^2 \times S^1 \times \real$, corresponding to:
\begin{itemize}
    \item $S^2$: Instrument pointing direction (2 DoF)
    \item $S^1$: Axial rotation about the instrument axis (1 DoF)
    \item $\real$: Insertion depth (1 DoF)
\end{itemize}
\end{proposition}

\begin{proof}
The constraint \eqref{eq:rcm_constraint} fixes the position $\mathbf{p}_E$ given $R_E$ and $d$, reducing the 6 DoF of $\SE(3)$ by 2 (the position is constrained to lie on the line through $\ptrocar$ with direction $R_E \mathbf{e}_z$). The remaining DoF correspond to: choosing the direction $R_E \mathbf{e}_z \in S^2$ (2 DoF), choosing the rotation about this axis (1 DoF, giving $S^1$), and choosing the depth $d$ (1 DoF, giving $\real$).
\end{proof}

\subsection{RCM-aware Action Space Parameterizations}

Rather than learning in $\SE(3)$ and projecting onto $\Mrcm$, we seek explicit parameterizations of $\Mrcm$ as the action space. We identify four natural parameterizations:

\begin{equation}
\boxed{
\begin{aligned}
    \xrcm^{(1)} &= (d_{\text{rel}}, R_{\text{rel}}) & & \text{[Relative depth, Relative rotation]} \\
    \xrcm^{(2)} &= (\gamrel, \prel) & & \text{[Relative roll, Relative position]} \\
    \xrcm^{(3)} &= (d_{\text{rel}}, R_{\text{abs}}) & & \text{[Relative depth, Absolute rotation]} \\
    \xrcm^{(4)} &= (\gamrel, \pabs) & & \text{[Relative roll, Absolute position]}
\end{aligned}
}
\label{eq:rcm_parameterizations}
\end{equation}

Here, ``relative'' quantities are expressed in the trocar frame $\{T\}$, while ``absolute'' quantities are expressed in the world frame $\{S\}$.

\begin{table}[t]
    \centering
    \caption{Comparison of RCM Action Space Parameterizations}
    \label{tab:rcm_comparison}
    \begin{tabular}{@{}lcccc@{}}
        \toprule
        \textbf{Property} & $\xrcm^{(1)}$ & $\xrcm^{(2)}$ & $\xrcm^{(3)}$ & $\xrcm^{(4)}$ \\
        \midrule
        Trocar-invariant component & \xmark & \xmark & $R_{\text{abs}}$ & $\pabs$ \\
        Geometric interpretability & High & Medium & Low & High \\
        Learning efficiency & Low & Low & Low & \textbf{High} \\
        Configuration consistency & -- & -- & Poor & \textbf{Good} \\
        \bottomrule
    \end{tabular}
\end{table}

\textbf{Analysis.} Parameterizations $\xrcm^{(1)}$ and $\xrcm^{(2)}$ are fully trocar-relative: all components depend on $\lambdatrocar$. Consequently, a policy must learn to map trocar parameters to appropriate actions, potentially requiring extensive trocar coverage during training.

Parameterizations $\xrcm^{(3)}$ and $\xrcm^{(4)}$ are partially trocar-invariant: one component (rotation or position) is expressed absolutely. This asymmetry has profound implications:

\begin{proposition}[Trocar-Invariance of Absolute Position]
\label{prop:invariance}
For visual servoing tasks where the target is defined by visual features in a fixed camera frame, the desired absolute position $\pabs^*$ is independent of trocar parameters $\lambdatrocar$.
\end{proposition}

\begin{proof}
Let the target object have world-frame position $\mathbf{p}_{\text{target}} \in \real^3$, determined solely by camera observations. The desired end-effector position for task completion is $\pabs^* = f_{\text{task}}(\mathbf{p}_{\text{target}})$, where $f_{\text{task}}$ encodes task-specific offsets (e.g., grasp approach). Since neither $\mathbf{p}_{\text{target}}$ nor $f_{\text{task}}$ depends on $\lambdatrocar$, the result follows.
\end{proof}

While $\xrcm^{(3)}$ also contains a trocar-invariant component ($R_{\text{abs}}$), it suffers from \textbf{configuration inconsistency}: the same $R_{\text{abs}}$ corresponds to vastly different instrument configurations depending on $\lambdatrocar$. This makes learning difficult, as similar rotation targets yield dissimilar physical behaviors.

In contrast, $\xrcm^{(4)}$ exhibits \textbf{configuration consistency}: the same $\pabs$ corresponds to similar instrument tip positions regardless of $\lambdatrocar$. The only variation is in the instrument's approach angle, which is captured by the trocar-dependent $\gamrel$.

Based on this analysis, we adopt $\xrcm^{(4)} = (\gamrel, \pabs)$ as our action space.

\subsection{Problem Statement}

We now state the trocar-adaptive surgical imitation learning problem:

\textbf{Given:}
\begin{itemize}
    \item A dataset $\mathcal{D} = \{(\tau_i, \lambda_i)\}_{i=1}^N$ of expert demonstrations, where $\tau_i = \{(o_t, a_t, g_t)\}_{t=1}^{T_i}$ contains observations $o_t$ (images), actions $a_t \in \xrcm^{(4)}$, and gripper states $g_t$, collected under trocar configuration $\lambda_i$.
    \item A distribution $p(\lambdatrocar)$ over trocar configurations.
\end{itemize}

\textbf{Find:} A policy $\pi(a \mid o, \lambdatrocar)$ that:
\begin{enumerate}
    \item Maximizes task success rate across $p(\lambdatrocar)$, including configurations not seen during training.
    \item Guarantees RCM constraint satisfaction by construction.
    \item Enables efficient inference for real-time control.
\end{enumerate}

%==============================================================================
% SECTION 4: METHODOLOGY
%==============================================================================
\section{Methodology}
\label{sec:methodology}

We present STAR-Diff, a hierarchical diffusion-based framework for trocar-adaptive surgical manipulation. Our approach exploits the decomposition of the RCM action space $\xrcm^{(4)} = (\gamrel, \pabs)$ into trocar-invariant (position) and trocar-dependent (rotation) components.

\subsection{Architecture Overview}

STAR-Diff comprises two modules (Fig.~\ref{fig:architecture}):

\begin{enumerate}
    \item \textbf{Absolute Position Diffusion Policy} $\pi_{\text{abs}}$: A conditional diffusion model that predicts future absolute positions $\pabs^{t+1:t+H}$ and gripper actions $g^{t+1:t+H}$, conditioned on visual observations $I^{t-T_o:t}$ and position history $\pabs^{t-T_o:t}$.
    
    \item \textbf{Relative Rotation Network} $f_{\text{rel}}$: A deterministic MLP that predicts relative roll $\gamrel^{t+1:t+H}$, conditioned on the diffusion output, trocar parameters $\lambdatrocar$, and roll history $\gamrel^{t-T_o:t}$.
\end{enumerate}

Here, $T_o$ is the observation horizon and $H$ is the prediction (action chunk) horizon.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/architecture.pdf}
    \caption{\textbf{STAR-Diff Architecture.} The diffusion policy predicts trocar-invariant absolute positions from visual observations. The deterministic network then computes trocar-dependent relative rotations conditioned on the diffusion output and trocar parameters.}
    \label{fig:architecture}
\end{figure}

\subsubsection{Rationale for Hierarchical Decomposition}

The decomposition is motivated by two observations:

\textit{Observation 1:} Absolute position prediction benefits from generative modeling. End-effector trajectories in manipulation tasks often exhibit multimodality (e.g., multiple valid grasp approaches) and complex temporal correlations. Diffusion models excel at capturing such distributions \cite{chi2023diffusion}.

\textit{Observation 2:} Given $\pabs$ and $\lambdatrocar$, the relative roll $\gamrel$ is nearly deterministic. Once the tip position and trocar location are known, the instrument's approach direction is constrained to pass through both points. The only remaining freedom is axial rotation, which is typically dictated by task requirements (e.g., gripper orientation for grasping) rather than exhibiting multimodality.

\subsection{Absolute Position Diffusion Policy}

We adopt the DDPM framework \cite{ho2020denoising} for position prediction. The diffusion model learns to reverse a forward noising process that gradually corrupts action sequences.

\subsubsection{Forward Process}

Given a clean action sequence $\mathbf{a}_0 = [\pabs^{t+1:t+H}, g^{t+1:t+H}]$, the forward process produces increasingly noisy versions:
\begin{equation}
    q(\mathbf{a}_k \mid \mathbf{a}_{k-1}) = \mathcal{N}(\mathbf{a}_k; \sqrt{1-\beta_k} \mathbf{a}_{k-1}, \beta_k \mathbf{I}),
\end{equation}
where $\{\beta_k\}_{k=1}^K$ is the noise schedule with $K$ diffusion steps. Using the reparameterization $\alpha_k = 1 - \beta_k$ and $\bar{\alpha}_k = \prod_{i=1}^k \alpha_i$, we can sample $\mathbf{a}_k$ directly:
\begin{equation}
    \mathbf{a}_k = \sqrt{\bar{\alpha}_k} \mathbf{a}_0 + \sqrt{1-\bar{\alpha}_k} \bm{\epsilon}, \quad \bm{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I}).
\end{equation}

\subsubsection{Reverse Process}

The reverse process learns to denoise, parameterized by a neural network $\epsilon_\theta$:
\begin{equation}
    p_\theta(\mathbf{a}_{k-1} \mid \mathbf{a}_k, \mathbf{c}) = \mathcal{N}(\mathbf{a}_{k-1}; \bm{\mu}_\theta(\mathbf{a}_k, \mathbf{c}, k), \sigma_k^2 \mathbf{I}),
\end{equation}
where $\mathbf{c} = (I^{t-T_o:t}, \pabs^{t-T_o:t})$ is the conditioning information.

\subsubsection{Training Objective}

We train by minimizing the simplified denoising objective:
\begin{equation}
    \mathcal{L}_{\text{abs}} = \mathbb{E}_{\mathbf{a}_0, k, \bm{\epsilon}} \left[ \| \bm{\epsilon} - \epsilon_\theta(\mathbf{a}_k, \mathbf{c}, k) \|^2 \right].
    \label{eq:diffusion_loss}
\end{equation}

\subsubsection{Network Architecture}

The noise prediction network $\epsilon_\theta$ follows the conditional U-Net architecture of \cite{chi2023diffusion}:

\textbf{Vision Encoder.} Images $I^{t-T_o:t}$ are encoded using a ResNet-18 backbone, pretrained on ImageNet and fine-tuned during training. We apply spatial softmax pooling to obtain a fixed-dimensional feature vector per frame:
\begin{equation}
    \mathbf{v}_t = \text{SpatialSoftmax}(\text{ResNet}(I_t)) \in \real^{d_v}.
\end{equation}

\textbf{State Encoder.} Position history $\pabs^{t-T_o:t}$ is encoded via a 1D convolutional network:
\begin{equation}
    \mathbf{s} = \text{Conv1D}(\pabs^{t-T_o:t}) \in \real^{d_s}.
\end{equation}

\textbf{Conditional U-Net.} The concatenated condition $\mathbf{c} = [\mathbf{v}_{t-T_o:t}, \mathbf{s}]$ is injected into a 1D U-Net that operates on the temporal dimension of action sequences. Diffusion timestep $k$ is encoded via sinusoidal embeddings and added to intermediate features.

\subsubsection{Inference}

At test time, we sample actions via iterative denoising:
\begin{equation}
    \mathbf{a}_{k-1} = \frac{1}{\sqrt{\alpha_k}} \left( \mathbf{a}_k - \frac{\beta_k}{\sqrt{1-\bar{\alpha}_k}} \epsilon_\theta(\mathbf{a}_k, \mathbf{c}, k) \right) + \sigma_k \mathbf{z},
\end{equation}
where $\mathbf{z} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ for $k > 1$ and $\mathbf{z} = \mathbf{0}$ for $k=1$. We use DDIM \cite{song2020denoising} for accelerated sampling with fewer steps.

\subsection{Relative Rotation Network}

The relative roll network $f_\phi$ is a deterministic MLP that completes the action by predicting trocar-dependent components.

\subsubsection{Input Representation}

Given the diffusion output $\pabs^{t+1:t+H}$, trocar parameters $\lambdatrocar$, and roll history $\gamrel^{t-T_o:t}$, we construct the input:
\begin{equation}
    \mathbf{x}_{\text{rel}} = [\pabs^{t+1:t+H}, \text{Embed}(\lambdatrocar), \gamrel^{t-T_o:t}],
\end{equation}
where $\text{Embed}(\cdot)$ is a learnable embedding for trocar parameters.

\subsubsection{Architecture}

The network $f_\phi$ consists of:
\begin{itemize}
    \item Linear projection: $\mathbf{x}_{\text{rel}} \mapsto \real^{256}$
    \item 3 residual MLP blocks with LayerNorm and GELU activation
    \item Output projection: $\real^{256} \mapsto \real^{H}$ (predicting $\gamrel^{t+1:t+H}$)
\end{itemize}

\subsubsection{Training}

The rotation network is trained jointly with the diffusion policy:
\begin{equation}
    \mathcal{L}_{\text{rel}} = \mathbb{E} \left[ \| \gamrel^{t+1:t+H} - f_\phi(\pabs^{t+1:t+H}, \lambdatrocar, \gamrel^{t-T_o:t}) \|^2 \right].
\end{equation}

The total loss is:
\begin{equation}
    \mathcal{L} = \mathcal{L}_{\text{abs}} + \lambda \mathcal{L}_{\text{rel}},
\end{equation}
where $\lambda$ balances the two terms (we use $\lambda = 0.1$).

\subsection{Action Execution via Forward Kinematics}

Given the predicted RCM action $(\gamrel^{t+1}, \pabs^{t+1})$, we recover the full end-effector pose for robot control:

\begin{algorithm}[t]
\caption{RCM Action to End-Effector Pose}
\label{alg:fk}
\begin{algorithmic}[1]
\REQUIRE Predicted action $(\gamrel, \pabs)$, trocar parameters $\lambdatrocar$
\ENSURE End-effector pose $(R_E, \mathbf{p}_E)$
\STATE Compute trocar position: $\ptrocar \leftarrow \text{Eq.}~\eqref{eq:trocar_position}$
\STATE Compute instrument direction: $\mathbf{v} \leftarrow \frac{\pabs - \ptrocar}{\|\pabs - \ptrocar\|}$
\STATE Compute base rotation aligning $\mathbf{e}_z$ to $\mathbf{v}$:
\STATE \quad $R_{\text{base}} \leftarrow \text{RotationAlign}(\mathbf{e}_z, \mathbf{v})$
\STATE Apply axial rotation:
\STATE \quad $R_E \leftarrow R_{\text{base}} \cdot R_z(\gamrel)$
\STATE Set position: $\mathbf{p}_E \leftarrow \pabs$
\RETURN $(R_E, \mathbf{p}_E)$
\end{algorithmic}
\end{algorithm}

The $\text{RotationAlign}(\mathbf{a}, \mathbf{b})$ function computes a rotation matrix that maps unit vector $\mathbf{a}$ to unit vector $\mathbf{b}$ using Rodrigues' formula:
\begin{equation}
    R = I + [\mathbf{k}]_\times + [\mathbf{k}]_\times^2 \frac{1}{1 + \mathbf{a} \cdot \mathbf{b}},
\end{equation}
where $\mathbf{k} = \mathbf{a} \times \mathbf{b}$ and $[\cdot]_\times$ denotes the skew-symmetric matrix.

Finally, we compute joint commands via inverse kinematics:
\begin{equation}
    \mathbf{q} = \text{IK}(R_E, \mathbf{p}_E),
\end{equation}
using a Jacobian-based iterative solver with the current configuration as the initial guess.

\subsection{RCM Constraint Guarantee}

\begin{theorem}[RCM Compliance by Construction]
Any action $(\gamrel, \pabs) \in \real \times \real^3$ produced by STAR-Diff, when converted to an end-effector pose via Algorithm~\ref{alg:fk}, satisfies the RCM constraint \eqref{eq:rcm_constraint}.
\end{theorem}

\begin{proof}
By construction, $\mathbf{p}_E = \pabs$ and the instrument direction is $\mathbf{v} = (\pabs - \ptrocar) / \|\pabs - \ptrocar\|$. Thus:
\begin{equation}
    \mathbf{p}_E = \ptrocar + \|\pabs - \ptrocar\| \cdot \mathbf{v} = \ptrocar + d \cdot R_E \mathbf{e}_z,
\end{equation}
where $d = \|\pabs - \ptrocar\|$ and $R_E \mathbf{e}_z = \mathbf{v}$ by the alignment construction. This matches \eqref{eq:rcm_constraint}.
\end{proof}

This guarantee is \textit{unconditional}: regardless of the values predicted by the neural networks, the resulting pose always satisfies RCM. This contrasts with penalty-based or projection-based approaches where constraint satisfaction is approximate.

\subsection{Training Data Collection}

To enable trocar generalization, we collect demonstrations across a distribution of trocar configurations.

\subsubsection{Trocar Sampling}

We sample trocar parameters from a uniform distribution:
\begin{equation}
    \lambdatrocar \sim \text{Uniform}([\underline{r}, \bar{r}] \times [\underline{\theta}, \bar{\theta}] \times [\underline{\phi}, \bar{\phi}]).
\end{equation}

Based on clinical guidelines for laparoscopic port placement \cite{reynolds2001practical}, we set:
\begin{itemize}
    \item $r \in [0, 5]$ cm (radial variation)
    \item $\theta \in [60°, 120°]$ (polar angle, avoiding extreme approach angles)
    \item $\phi \in [0°, 360°]$ (full azimuthal coverage)
\end{itemize}

\subsubsection{Demonstration Protocol}

For each sampled $\lambdatrocar$:
\begin{enumerate}
    \item Configure the simulation/robot with the corresponding trocar position.
    \item An expert teleoperator performs the task using a 6-DoF input device.
    \item Record synchronized streams: images (30 Hz), end-effector pose, gripper state.
    \item Convert poses to RCM action space representation $(\gamrel, \pabs)$.
\end{enumerate}

We collect 20-30 demonstrations per trocar configuration across 10-15 configurations per task, yielding 200-450 demonstrations per task.

\subsection{Implementation Details}

\textbf{Network Hyperparameters.}
\begin{itemize}
    \item Vision encoder: ResNet-18, output dimension $d_v = 512$
    \item State encoder: 3-layer Conv1D, output dimension $d_s = 256$
    \item U-Net: 4 downsampling/upsampling blocks, base channels 256
    \item Rotation MLP: 3 residual blocks, hidden dimension 256
\end{itemize}

\textbf{Diffusion Hyperparameters.}
\begin{itemize}
    \item Diffusion steps: $K = 100$ (training), 10 (DDIM inference)
    \item Noise schedule: Cosine \cite{nichol2021improved}
    \item Observation horizon: $T_o = 2$
    \item Prediction horizon: $H = 16$
    \item Action execution: First 8 actions executed before replanning
\end{itemize}

\textbf{Training.}
\begin{itemize}
    \item Optimizer: AdamW, learning rate $1 \times 10^{-4}$, weight decay $1 \times 10^{-6}$
    \item Batch size: 256
    \item Training iterations: 100K
    \item Data augmentation: Random crop, color jitter, Gaussian noise
\end{itemize}

%==============================================================================
% SECTION 5: EXPERIMENTS
%==============================================================================
\section{Experiments}
\label{sec:experiments}

We design a unified experiment to answer three research questions through systematic comparison:
\begin{itemize}
    \item \textbf{RQ1}: Does STAR-Diff generalize to unseen trocar positions?
    \item \textbf{RQ2}: How effective is the RCM-aware action space compared to naive action spaces?
    \item \textbf{RQ3}: Does the hierarchical architecture provide benefits over a single-model approach?
\end{itemize}

By comparing all methods on the same task with the unified metric of \textbf{task success rate} across seen and unseen trocar configurations, we can simultaneously address all research questions.

\subsection{Experimental Setup}

\subsubsection{Task: Peg Transfer}

We evaluate on the \textbf{Peg Transfer} task from the Fundamentals of Laparoscopic Surgery (FLS) benchmark \cite{peters2004development}. This task requires picking up a peg from one board and transferring it to a target location on another board. It tests fundamental skills including depth perception, hand-eye coordination, and precise manipulation under RCM constraints.

The task is implemented in a simulation environment based on SurRoL \cite{xu2021surrol} with realistic physics and visual rendering. The robot is a 6-DoF Fairino FR5 manipulator equipped with a laparoscopic grasper.

\subsubsection{Trocar Configuration}

We define a trocar distribution covering clinically relevant variations:
\begin{itemize}
    \item Radial distance: $r \in [0, 5]$ cm
    \item Polar angle: $\theta \in [70°, 110°]$
    \item Azimuthal angle: $\phi \in [0°, 360°]$
\end{itemize}

We discretize this space into 12 trocar configurations:
\begin{itemize}
    \item \textbf{Training set}: 8 configurations (67\%), uniformly distributed
    \item \textbf{Test set (Seen)}: Same 8 configurations as training
    \item \textbf{Test set (Unseen)}: 4 held-out configurations (33\%), including boundary cases
\end{itemize}

\subsubsection{Data Collection}

Expert demonstrations are collected via teleoperation using a SpaceMouse 6-DoF input device. For each trocar configuration in the training set, we collect 30 successful demonstrations, yielding 240 total demonstrations recorded at 30 Hz (RGB images at 256$\times$256, end-effector poses, gripper states).

\subsubsection{Evaluation Protocol}

All methods are evaluated using \textbf{Task Success Rate (SR)}: the percentage of trials where the peg is successfully transferred within 60 seconds. Each method is evaluated over 30 trials per trocar configuration (240 trials for seen, 120 trials for unseen).

We define the \textbf{generalization gap} as:
\begin{equation}
    \Delta_{\text{gen}} = \text{SR}_{\text{seen}} - \text{SR}_{\text{unseen}}.
\end{equation}
A smaller gap indicates better generalization to novel trocar configurations.

\subsection{Methods Compared}

To systematically isolate the effects of action space design and architecture, we compare 8 methods organized into three groups (Table~\ref{tab:methods}).

\begin{table}[t]
    \centering
    \caption{Summary of Compared Methods}
    \label{tab:methods}
    \resizebox{\columnwidth}{!}{
    \begin{tabular}{@{}llccc@{}}
        \toprule
        \textbf{Group} & \textbf{Method} & \textbf{Action Space} & \textbf{RCM} & \textbf{Arch.} \\
        \midrule
        \multirow{2}{*}{\textit{Naive}} 
        & DP-EE & $\SE(3)$ & None & Single \\
        & DP-EE-Proj & $\SE(3)$ & Post-hoc & Single \\
        \midrule
        \multirow{4}{*}{\textit{RCM Action Spaces}} 
        & DP-RCM-1 & $(d_{\text{rel}}, R_{\text{rel}})$ & By constr. & Single \\
        & DP-RCM-2 & $(\gamrel, \prel)$ & By constr. & Single \\
        & DP-RCM-3 & $(d_{\text{rel}}, R_{\text{abs}})$ & By constr. & Single \\
        & DP-RCM-4 & $(\gamrel, \pabs)$ & By constr. & Single \\
        \midrule
        \multirow{2}{*}{\textit{Ours}} 
        & STAR-Diff-Single & $(\gamrel, \pabs)$ & By constr. & Single \\
        & \textbf{STAR-Diff} & $(\gamrel, \pabs)$ & By constr. & \textbf{Hier.} \\
        \bottomrule
    \end{tabular}
    }
    \vspace{0.5em}
    
    {\footnotesize All methods use Diffusion Policy as the base architecture. ``By constr.'' = RCM satisfied by construction. ``Hier.'' = Hierarchical (diffusion + MLP).}
\end{table}

\textbf{Group 1: Naive Action Spaces.}
\begin{itemize}
    \item \textbf{DP-EE}: Vanilla Diffusion Policy predicting end-effector pose in $\SE(3)$. No RCM handling.
    \item \textbf{DP-EE-Proj}: Same as DP-EE, but with post-hoc projection onto the RCM constraint manifold at execution time.
\end{itemize}

\textbf{Group 2: RCM Action Spaces (Single Model).} Four variants corresponding to the parameterizations in Eq.~\eqref{eq:rcm_parameterizations}:
\begin{itemize}
    \item \textbf{DP-RCM-1}: $\xrcm^{(1)} = (d_{\text{rel}}, R_{\text{rel}})$ — fully relative, depth + rotation.
    \item \textbf{DP-RCM-2}: $\xrcm^{(2)} = (\gamrel, \prel)$ — fully relative, roll + position.
    \item \textbf{DP-RCM-3}: $\xrcm^{(3)} = (d_{\text{rel}}, R_{\text{abs}})$ — mixed, depth relative + rotation absolute.
    \item \textbf{DP-RCM-4}: $\xrcm^{(4)} = (\gamrel, \pabs)$ — mixed, roll relative + position absolute.
\end{itemize}
All use a single diffusion model conditioned on trocar parameters $\lambdatrocar$.

\textbf{Group 3: Our Methods.}
\begin{itemize}
    \item \textbf{STAR-Diff-Single}: Uses $\xrcm^{(4)}$ with a single diffusion model (ablation for RQ3).
    \item \textbf{STAR-Diff}: Uses $\xrcm^{(4)}$ with hierarchical architecture—diffusion for $\pabs$, deterministic MLP for $\gamrel$.
\end{itemize}

Note that \textbf{STAR-Diff-Single} and \textbf{DP-RCM-4} are identical, listed in both groups to clarify comparisons.

\subsection{Results}

Table~\ref{tab:main_results} presents the unified comparison across all methods.

\begin{table}[t]
    \centering
    \caption{Task Success Rate (\%) on Peg Transfer}
    \label{tab:main_results}
    \resizebox{\columnwidth}{!}{
    \begin{tabular}{@{}llccc@{}}
        \toprule
        \textbf{Group} & \textbf{Method} & \textbf{Seen}$\uparrow$ & \textbf{Unseen}$\uparrow$ & $\Delta_{\text{gen}}$$\downarrow$ \\
        \midrule
        \multirow{2}{*}{\textit{Naive}} 
        & DP-EE & \texttt{[XX.X]} & \texttt{[XX.X]} & \texttt{[XX.X]} \\
        & DP-EE-Proj & \texttt{[XX.X]} & \texttt{[XX.X]} & \texttt{[XX.X]} \\
        \midrule
        \multirow{4}{*}{\textit{RCM Actions}} 
        & DP-RCM-1 $(d_{\text{rel}}, R_{\text{rel}})$ & \texttt{[XX.X]} & \texttt{[XX.X]} & \texttt{[XX.X]} \\
        & DP-RCM-2 $(\gamrel, \prel)$ & \texttt{[XX.X]} & \texttt{[XX.X]} & \texttt{[XX.X]} \\
        & DP-RCM-3 $(d_{\text{rel}}, R_{\text{abs}})$ & \texttt{[XX.X]} & \texttt{[XX.X]} & \texttt{[XX.X]} \\
        & DP-RCM-4 $(\gamrel, \pabs)$ & \texttt{[XX.X]} & \texttt{[XX.X]} & \texttt{[XX.X]} \\
        \midrule
        \multirow{2}{*}{\textit{Ours}} 
        & STAR-Diff-Single & \texttt{[XX.X]} & \texttt{[XX.X]} & \texttt{[XX.X]} \\
        & \textbf{STAR-Diff} & \texttt{[\textbf{XX.X}]} & \texttt{[\textbf{XX.X}]} & \texttt{[\textbf{XX.X}]} \\
        \bottomrule
    \end{tabular}
    }
    \vspace{0.5em}
    
    {\footnotesize Results averaged over 30 trials per trocar (240 seen, 120 unseen). Best in \textbf{bold}.}
\end{table}

\subsubsection{Analysis for RQ1: Generalization to Unseen Trocars}

Comparing the ``Unseen'' column and $\Delta_{\text{gen}}$ across all methods reveals generalization capability.

\textbf{Expected Findings:}
\begin{itemize}
    \item \textbf{DP-EE} should show the largest generalization gap, as the learned trajectories are tied to specific trocar configurations.
    \item \textbf{RCM action space methods} (DP-RCM-1 to 4) should show varying generalization depending on their trocar-invariant properties.
    \item \textbf{STAR-Diff} should achieve the smallest $\Delta_{\text{gen}}$ due to its trocar-invariant absolute position prediction.
\end{itemize}

\subsubsection{Analysis for RQ2: RCM-aware vs. Naive Action Space}

Comparing Group 1 (Naive) vs. Groups 2-3 (RCM-aware) isolates the effect of action space design.

\textbf{Expected Findings:}
\begin{itemize}
    \item \textbf{DP-EE} should achieve reasonable success on seen trocars but with implicit RCM violations that may cause failures.
    \item \textbf{DP-EE-Proj} should improve over DP-EE by enforcing RCM, but post-hoc projection may introduce discontinuities that hurt performance.
    \item \textbf{All RCM action space methods} guarantee zero RCM violations by construction, leading to more reliable execution.
    \item Among RCM parameterizations, $\xrcm^{(4)} = (\gamrel, \pabs)$ should perform best due to configuration consistency (Section~\ref{sec:problem_formulation}).
\end{itemize}

\subsubsection{Analysis for RQ3: Hierarchical vs. Single Architecture}

Comparing \textbf{STAR-Diff-Single} (= DP-RCM-4) vs. \textbf{STAR-Diff} isolates the benefit of hierarchical decomposition.

\textbf{Expected Findings:}
\begin{itemize}
    \item Both methods use the same action space $\xrcm^{(4)}$, so differences arise purely from architecture.
    \item \textbf{STAR-Diff-Single} must learn to predict both $\pabs$ and $\gamrel$ jointly, with $\gamrel$ depending on trocar parameters.
    \item \textbf{STAR-Diff} decouples: the diffusion model predicts only trocar-invariant $\pabs$, while a simple MLP handles $\gamrel$.
    \item The hierarchical design should yield better generalization (smaller $\Delta_{\text{gen}}$) by allowing the diffusion model to focus on task-relevant multimodality without trocar-induced variation.
\end{itemize}

\subsection{Qualitative Analysis}

Figure~\ref{fig:qualitative} visualizes representative rollout trajectories.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/qualitative.pdf}
    \caption{\textbf{Qualitative Comparison.} Rollout trajectories across three trocar configurations (columns) for selected methods. Trocar points marked with $\times$. Top row: seen trocars. Bottom row: unseen trocars. \texttt{[PLACEHOLDER]}}
    \label{fig:qualitative}
\end{figure}

\textbf{Expected Observations:}
\begin{itemize}
    \item \textbf{DP-EE}: Trajectories may deviate from RCM constraint, especially for unseen trocars.
    \item \textbf{DP-RCM-1/2} (fully relative): Valid trajectories but may struggle to adapt to unseen trocars.
    \item \textbf{DP-RCM-3}: Poor performance due to configuration inconsistency of $R_{\text{abs}}$.
    \item \textbf{STAR-Diff}: Smooth, RCM-compliant trajectories that adapt naturally across trocar positions.
\end{itemize}

\subsection{Additional Analysis}

\subsubsection{Performance vs. Trocar Distance}

Figure~\ref{fig:trocar_distance} analyzes how success rate degrades as test trocars deviate from the training distribution.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.85\columnwidth]{figures/trocar_distance.pdf}
    \caption{\textbf{Success Rate vs. Trocar Distance from Training Set.} Methods with trocar-invariant representations should degrade more gracefully. \texttt{[PLACEHOLDER]}}
    \label{fig:trocar_distance}
\end{figure}

\subsubsection{Computational Overhead}

\begin{table}[t]
    \centering
    \caption{Inference Time Comparison}
    \label{tab:computation}
    \begin{tabular}{@{}lcc@{}}
        \toprule
        \textbf{Method} & \textbf{Time (ms)} & \textbf{Freq. (Hz)} \\
        \midrule
        DP-EE / DP-RCM-* / Single & \texttt{[XX]} & \texttt{[XX]} \\
        \textbf{STAR-Diff} & \texttt{[XX]} & \texttt{[XX]} \\
        \bottomrule
    \end{tabular}
    
    {\footnotesize Measured on RTX 3090 with DDIM (10 steps).}
\end{table}

\textbf{Expected:} The additional MLP in STAR-Diff introduces $<$1ms overhead, maintaining real-time control.

%==============================================================================
% SECTION 6: DISCUSSION AND CONCLUSION
%==============================================================================
\section{Discussion and Conclusion}
\label{sec:conclusion}

\subsection{Discussion}

\textbf{Limitations.} Our current work has several limitations that suggest directions for future research:

\textit{(1) 6-DoF Manipulator Constraint.} STAR-Diff is designed for standard 6-DoF manipulators without articulated wrists. While this democratizes surgical automation research, it limits the dexterity compared to systems like da Vinci with EndoWrist. Extending our framework to 7+ DoF systems with redundant kinematics is an important direction.

\textit{(2) Single Fixed Camera.} We assume a fixed monocular camera observing the workspace. Clinical laparoscopy typically uses an endoscopic camera inserted through a separate trocar, which moves during the procedure. Incorporating dynamic camera poses into our framework would enhance clinical applicability.

\textit{(3) Single-Arm Evaluation.} Our experiments focus on single-arm peg transfer. Extending to bimanual tasks (e.g., suturing) where both arms must coordinate while respecting individual RCM constraints presents additional challenges.

\textit{(4) Simulation-Only Evaluation.} While our simulation environment provides realistic physics and visuals, validation on physical hardware is necessary to assess sim-to-real transfer and real-world robustness.

\textbf{Broader Impact.} By enabling surgical policies that generalize across trocar configurations, STAR-Diff takes a step toward clinically deployable autonomous surgical systems. The use of commodity manipulators rather than proprietary platforms could reduce barriers to surgical robotics research and potentially lower costs of surgical automation. However, autonomous surgery raises significant safety and ethical considerations that must be carefully addressed before clinical deployment.

\subsection{Conclusion}

We presented STAR-Diff, a diffusion-based imitation learning framework for trocar-adaptive surgical manipulation. Our key contributions are:

\begin{enumerate}
    \item \textbf{RCM-aware Action Space}: By directly parameterizing the RCM constraint manifold, we guarantee constraint satisfaction by construction, eliminating the need for post-hoc enforcement mechanisms.
    
    \item \textbf{Hierarchical Architecture}: By decomposing the action space into trocar-invariant (absolute position) and trocar-dependent (relative rotation) components, we enable efficient learning that generalizes across trocar configurations.
    
    \item \textbf{Theoretical Foundation}: We provided geometric analysis of the RCM constraint structure and formal guarantees of constraint satisfaction.
\end{enumerate}

\texttt{[To be updated after experiments:} Our experiments on the peg transfer task demonstrate that STAR-Diff achieves [XX\%] success rate on unseen trocar configurations, compared to [XX\%] for the best baseline, while maintaining zero RCM violations.\texttt{]}

Looking forward, we envision extending STAR-Diff to more complex surgical tasks, bimanual manipulation, and real-world deployment. The principles of constraint-aware action space design and trocar-invariant decomposition may also apply to other constrained manipulation domains beyond surgery.

%==============================================================================
% REFERENCES (Placeholder entries)
%==============================================================================
\bibliographystyle{IEEEtran}
\begin{thebibliography}{99}

\bibitem{mack2001minimally}
M. J. Mack, ``Minimally invasive and robotic surgery,'' \textit{JAMA}, vol. 285, no. 5, pp. 568--572, 2001.

\bibitem{intuitive2023davinci}
Intuitive Surgical, ``da Vinci Surgical System,'' 2023. [Online]. Available: \url{https://www.intuitive.com/}

\bibitem{chi2023diffusion}
C. Chi, S. Feng, Y. Du, Z. Xu, E. Cousineau, B. Burchfiel, and S. Song, ``Diffusion policy: Visuomotor policy learning via action diffusion,'' in \textit{Proc. RSS}, 2023.

\bibitem{zhao2023learning}
T. Z. Zhao, V. Kumar, S. Levine, and C. Finn, ``Learning fine-grained bimanual manipulation with low-cost hardware,'' in \textit{Proc. RSS}, 2023.

\bibitem{scheikl2024movement}
S. Scheikl \textit{et al.}, ``Movement primitive diffusion for dexterous surgical manipulation,'' in \textit{Proc. ICRA}, 2024.

\bibitem{xu2021surrol}
J. Xu \textit{et al.}, ``SurRoL: An open-source reinforcement learning centered and dVRK compatible platform for surgical robot learning,'' in \textit{Proc. IROS}, 2021.

\bibitem{reynolds2001practical}
W. Reynolds, ``The first laparoscopic cholecystectomy,'' \textit{JSLS}, vol. 5, no. 1, pp. 89--94, 2001.

\bibitem{murphy2001surgeon}
D. Murphy \textit{et al.}, ``Surgeon preferences and peritoneal access,'' \textit{Surg. Endosc.}, vol. 15, pp. 1236--1240, 2001.

\bibitem{taylor1999steady}
R. H. Taylor \textit{et al.}, ``A steady-hand robotic system for microsurgical augmentation,'' \textit{Int. J. Robot. Res.}, vol. 18, no. 12, pp. 1201--1210, 1999.

\bibitem{sandoval2017collaborative}
J. Sandoval \textit{et al.}, ``Collaborative framework for robot-assisted minimally invasive surgery,'' in \textit{Proc. ICRA}, 2017.

\bibitem{lu2021super}
J. Lu \textit{et al.}, ``Super: A surgical perception framework for endoscopic tissue manipulation,'' \textit{IEEE RA-L}, vol. 6, no. 2, pp. 3977--3984, 2021.

\bibitem{yu2024orbit}
Y. Yu \textit{et al.}, ``ORBIT-Surgical: An open-simulation framework for learning surgical augmented dexterity,'' in \textit{Proc. ICRA}, 2024.

\bibitem{van2010superhuman}
J. van den Berg \textit{et al.}, ``Superhuman performance of surgical tasks by robots using iterative learning,'' in \textit{Proc. ICRA}, 2010.

\bibitem{schulman2013case}
J. Schulman \textit{et al.}, ``A case study of trajectory transfer through non-rigid registration for a simplified suturing scenario,'' in \textit{Proc. IROS}, 2013.

\bibitem{thananjeyan2017multilateral}
B. Thananjeyan \textit{et al.}, ``Multilateral surgical pattern cutting in 2D orthotropic gauze with deep reinforcement learning policies for tensioning,'' in \textit{Proc. ICRA}, 2017.

\bibitem{varier2020collaborative}
V. M. Varier \textit{et al.}, ``Collaborative suturing: A reinforcement learning approach,'' in \textit{Proc. CASE}, 2020.

\bibitem{guthart2000intuitive}
G. S. Guthart and J. K. Salisbury, ``The Intuitive telesurgery system: Overview and application,'' in \textit{Proc. ICRA}, 2000.

\bibitem{simaan2009design}
N. Simaan \textit{et al.}, ``Design and integration of a telerobotic system for minimally invasive surgery of the throat,'' \textit{Int. J. Robot. Res.}, vol. 28, no. 9, pp. 1134--1153, 2009.

\bibitem{locke2007optimal}
R. C. Locke and R. V. Patel, ``Optimal remote center-of-motion location for robotics-assisted minimally-invasive surgery,'' in \textit{Proc. ICRA}, 2007.

\bibitem{selvaggio2018safe}
M. Selvaggio \textit{et al.}, ``Safe and efficient autonomous navigation for teleoperation in surgery,'' \textit{IEEE RA-L}, vol. 3, no. 4, pp. 3373--3380, 2018.

\bibitem{richter2021open}
F. Richter \textit{et al.}, ``Open-sourced reinforcement learning environments for surgical robotics,'' in \textit{Proc. IROS}, 2021.

\bibitem{tobin2017domain}
J. Tobin \textit{et al.}, ``Domain randomization for transferring deep neural networks from simulation to the real world,'' in \textit{Proc. IROS}, 2017.

\bibitem{tzeng2020adapting}
E. Tzeng \textit{et al.}, ``Adapting deep visuomotor representations with weak pairwise constraints,'' in \textit{Proc. WAFR}, 2020.

\bibitem{simeonov2022neural}
A. Simeonov \textit{et al.}, ``Neural descriptor fields: SE(3)-equivariant object representations for manipulation,'' in \textit{Proc. ICRA}, 2022.

\bibitem{da2012learning}
B. Da Silva \textit{et al.}, ``Learning parameterized skills,'' in \textit{Proc. ICML}, 2012.

\bibitem{finn2017model}
C. Finn \textit{et al.}, ``Model-agnostic meta-learning for fast adaptation of deep networks,'' in \textit{Proc. ICML}, 2017.

\bibitem{kazanzides2014open}
P. Kazanzides \textit{et al.}, ``An open-source research kit for the da Vinci surgical system,'' in \textit{Proc. ICRA}, 2014.

\bibitem{shin2019autonomous}
C. Shin \textit{et al.}, ``Autonomous tissue manipulation via surgical robot using learning based model predictive control,'' in \textit{Proc. ICRA}, 2019.

\bibitem{ho2020denoising}
J. Ho, A. Jain, and P. Abbeel, ``Denoising diffusion probabilistic models,'' in \textit{Proc. NeurIPS}, 2020.

\bibitem{song2020score}
Y. Song \textit{et al.}, ``Score-based generative modeling through stochastic differential equations,'' in \textit{Proc. ICLR}, 2021.

\bibitem{ze20243d}
Y. Ze \textit{et al.}, ``3D diffusion policy,'' in \textit{Proc. RSS}, 2024.

\bibitem{ajay2022conditional}
A. Ajay \textit{et al.}, ``Is conditional generative modeling all you need for decision-making?'' in \textit{Proc. ICLR}, 2023.

\bibitem{reuss2023goal}
M. Reuss \textit{et al.}, ``Goal-conditioned imitation learning using score-based diffusion policies,'' in \textit{Proc. RSS}, 2023.

\bibitem{chi2024universal}
C. Chi \textit{et al.}, ``Universal manipulation interface,'' in \textit{Proc. RSS}, 2024.

\bibitem{prasad2024consistency}
V. Prasad \textit{et al.}, ``Consistency policy: Accelerated visuomotor policies via consistency distillation,'' in \textit{Proc. RSS}, 2024.

\bibitem{song2020denoising}
J. Song, C. Meng, and S. Ermon, ``Denoising diffusion implicit models,'' in \textit{Proc. ICLR}, 2021.

\bibitem{nichol2021improved}
A. Nichol and P. Dhariwal, ``Improved denoising diffusion probabilistic models,'' in \textit{Proc. ICML}, 2021.

\bibitem{peters2004development}
J. H. Peters \textit{et al.}, ``Development and validation of a comprehensive program of education and assessment of the basic fundamentals of laparoscopic surgery,'' \textit{Surgery}, vol. 135, no. 1, pp. 21--27, 2004.

\end{thebibliography}

\end{document}